{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#warnings.filterwarnings('ignore')\n",
    "# BEWARE, ignoreing warnings is not always a good idea\n",
    "# I am doing it for presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Private and Encrypted AI - Credit Approval Application\n",
    "\n",
    "This notebook is meant for my exploratory development of en encrypted federated deep learning approach.\n",
    "I will develop a final model in a separate folder.\n",
    "\n",
    "### Glossary\n",
    "1. [Data Preparation & Setup](#data_prep)\n",
    "2. [Classical Deep Learning](#classical_dl)\n",
    "3. [Federated Deep Learning](#federated_dl)<br>\n",
    "    3.1 [Model Averaging with Trusted Aggregator](#fl_model_avg)\n",
    "4. [Encrypted Deep Learning](#encrypted_dl)<br>\n",
    "   4.1 [Secured Multi-Party Computation (SMPC)](#smpc) <br>\n",
    "   4.2 [Encrypted Gradient Averaging](#fl_encrypt_avg)<br>\n",
    "   4.3 [Differential Privacy for DL](#dp_dl)\n",
    "   \n",
    "<hr>\n",
    "\n",
    "_Notes_ <br>This project was inspired by lectures of [Andrew Trask](https://iamtrask.github.io/) in the [Private AI Scholarship Challenge on Udacity](https://www.udacity.com/facebook-AI-scholarship). Furthermore, segments of the code are inspired by the [PySyft tutorials on GitHub](https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials); an excellent resource for people starting off with Private AI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_prep'></a>\n",
    "## Data Preparation\n",
    "- only using non-NaN values. I drop NaN values because the dataset is not very big regardless, and we are not dropping very many values.\n",
    "- Convert binary variables to a numeric representation, and one-hot-encode categorical variables. We do not want to use label encoder since a label encoder would make it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ f\"A{i}\" for i in range(1,16)]\n",
    "cols.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653, 16) \n",
      " ------- \n",
      "\n",
      "  A1     A2    A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 label\n",
      "0  b  30.83  0.00  u  g  w  v  1.25  t   t    1   f   g  00202    0     +\n",
      "1  a  58.67  4.46  u  g  q  h  3.04  t   t    6   f   g  00043  560     +\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/crx.data', names=cols)\\\n",
    "    .replace(to_replace='?', value=np.nan).dropna()\n",
    "print(df.shape, \"\\n ------- \\n\")\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "Let's check out what this data looks like first, so that we have an idea of what we are dealing with. In true encrypted, federated learning we would not have this luxury though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def to_binary(df, col):\n",
    "    u = df[col].unique()\n",
    "    mapping =dict(zip(u, [i for i in range(0,len(u))]))\n",
    "    return df[col].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    b\n",
       "1    a\n",
       "2    a\n",
       "3    b\n",
       "4    b\n",
       "Name: A1, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.A1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to float\n",
    "for col in ['A2', 'A3', 'A8', 'A11', 'A14', 'A15']:\n",
    "    df[col] = df[col].astype(float)\n",
    "    \n",
    "#binarize\n",
    "for col in ['A1', 'A9', 'A10', 'A12', 'label']:\n",
    "    df[col] = to_binary(df, col)\n",
    "    \n",
    "onehot_cols = ['A4', 'A5', 'A6', 'A7', 'A13']\n",
    "\n",
    "#perform one hot encoding, and drop original columns\n",
    "df  = df.join(pd.get_dummies(df[onehot_cols], dtype=int))\\\n",
    "                                .drop(onehot_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'), dtype('float64')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.dtypes) #check that we have the data types we expect, no object types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.504</td>\n",
       "      <td>4.830</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.502</td>\n",
       "      <td>180.360</td>\n",
       "      <td>1013.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.838</td>\n",
       "      <td>5.027</td>\n",
       "      <td>3.371</td>\n",
       "      <td>4.968</td>\n",
       "      <td>168.297</td>\n",
       "      <td>5253.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.580</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.420</td>\n",
       "      <td>2.835</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>160.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.250</td>\n",
       "      <td>7.500</td>\n",
       "      <td>2.625</td>\n",
       "      <td>3.000</td>\n",
       "      <td>272.000</td>\n",
       "      <td>400.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76.750</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.500</td>\n",
       "      <td>67.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A2      A3      A8     A11       A14         A15\n",
       "mean  31.504   4.830   2.244   2.502   180.360    1013.761\n",
       "std   11.838   5.027   3.371   4.968   168.297    5253.279\n",
       "min   13.750   0.000   0.000   0.000     0.000       0.000\n",
       "25%   22.580   1.040   0.165   0.000    73.000       0.000\n",
       "50%   28.420   2.835   1.000   0.000   160.000       5.000\n",
       "75%   38.250   7.500   2.625   3.000   272.000     400.000\n",
       "max   76.750  28.000  28.500  67.000  2000.000  100000.000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distribution of numeric-only columns\n",
    "df[['A2', 'A3', 'A8', 'A11', 'A14', 'A15']].describe().iloc[1:, :10].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>...</th>\n",
       "      <th>A7_ff</th>\n",
       "      <th>A7_h</th>\n",
       "      <th>A7_j</th>\n",
       "      <th>A7_n</th>\n",
       "      <th>A7_o</th>\n",
       "      <th>A7_v</th>\n",
       "      <th>A7_z</th>\n",
       "      <th>A13_g</th>\n",
       "      <th>A13_p</th>\n",
       "      <th>A13_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2    A3    A8  A9  A10  A11  A12    A14    A15  ...  A7_ff  A7_h  \\\n",
       "0   0  30.83  0.00  1.25   0    0  1.0    0  202.0    0.0  ...      0     0   \n",
       "1   1  58.67  4.46  3.04   0    0  6.0    0   43.0  560.0  ...      0     1   \n",
       "\n",
       "   A7_j  A7_n  A7_o  A7_v  A7_z  A13_g  A13_p  A13_s  \n",
       "0     0     0     0     1     0      1      0      0  \n",
       "1     0     0     0     0     0      1      0      0  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2) #double check what our DF looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Real People's Data\n",
    "\n",
    "To illustrate how this model would work in real life, I want to simulate this data belonging to people. I am generating random names to be associated with each row. I know that this is not an ideal example since I am in fact starting with the data all collated on my computer with peoples names and data being directly exposed. Not private at all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thelma Hoyle'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import names #used to get random names\n",
    "names.get_first_name()+' ' +names.get_last_name() #call random name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "used_names = set()\n",
    "for idx in range(len(df)):\n",
    "    name = names.get_first_name()+' ' +names.get_last_name()\n",
    "    while name in used_names:\n",
    "        name = names.get_first_name()+' ' +names.get_last_name()\n",
    "        \n",
    "    used_names.add(name)\n",
    "    users.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>...</th>\n",
       "      <th>A7_h</th>\n",
       "      <th>A7_j</th>\n",
       "      <th>A7_n</th>\n",
       "      <th>A7_o</th>\n",
       "      <th>A7_v</th>\n",
       "      <th>A7_z</th>\n",
       "      <th>A13_g</th>\n",
       "      <th>A13_p</th>\n",
       "      <th>A13_s</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Stuart Pettrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Steven Narro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2    A3    A8  A9  A10  A11  A12    A14    A15  ...  A7_h  A7_j  \\\n",
       "0   0  30.83  0.00  1.25   0    0  1.0    0  202.0    0.0  ...     0     0   \n",
       "1   1  58.67  4.46  3.04   0    0  6.0    0   43.0  560.0  ...     1     0   \n",
       "\n",
       "   A7_n  A7_o  A7_v  A7_z  A13_g  A13_p  A13_s            name  \n",
       "0     0     0     1     0      1      0      0  Stuart Pettrey  \n",
       "1     0     0     0     0      1      0      0    Steven Narro  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'] = users\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features and labels as numpy arrays which we can convert to tensors\n",
    "features = df.drop(['label', 'name'], axis=1).values.astype(float)\n",
    "labels = df['label'].values.astype(float)\n",
    "\n",
    "\n",
    "#normalize\n",
    "sclr = MinMaxScaler()\n",
    "features = sclr.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save features and labels for future use\n",
    "np.save('data/features', features)\n",
    "np.save('data/labels', labels)\n",
    "\n",
    "#save labels where shape is (1,2)\n",
    "labels=pd.get_dummies(df['label']).values.astype(float)\n",
    "np.save('data/labels_dim', labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Please Note_ <br>\n",
    "Normalization is not necessary per se for any machine learning algorithm, but it is recommended for deep learning for training purposes. Read more [here](https://datascience.stackexchange.com/a/13221/60648).\n",
    "\n",
    "## Model Development\n",
    "I am using PyTorch to create a neural network to classify whether someone is accepted for credit or not. PyTorch integrates will with PySyft, the package used to encrypt our deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import syft as sy\n",
    "import torch as th\n",
    "th.manual_seed(42) #so that dropout affects same layers\n",
    "\n",
    "data = th.tensor(features, dtype=th.float32, requires_grad=True)\n",
    "target = th.tensor(labels, dtype=th.float32, requires_grad=False).reshape(-1,2)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    '''\n",
    "    Neural Network Example Model\n",
    "    \n",
    "    Attributes\n",
    "    :hidden_layers (nn.ModuleList) - hidden units and dimensions for each layer\n",
    "    :output (nn.Linear) - final fully-connected layer to handle output for model\n",
    "    :dropout (nn.Dropout) - handling of layer-wise drop-out parameter\n",
    "    \n",
    "    Functions\n",
    "    :forward - handling of forward pass of datum through the network.\n",
    "    '''\n",
    "    def __init__(self, args):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(args.in_size,\n",
    "                                                      args.hidden_layers[0])])\n",
    "\n",
    "        #create hidden layers\n",
    "        layer_sizes = zip(args.hidden_layers[:-1], args.hidden_layers[1:]) \n",
    "        #gives input/output sizes for each layer\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        self.output = nn.Linear(args.hidden_layers[-1], args.out_size)\n",
    "        self.dropout = None if args.drop_p is None \\\n",
    "                                            else nn.Dropout(p=args.drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, args.in_size)\n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x)) #apply relu to each hidden node\n",
    "            \n",
    "            if self.dropout is not None:\n",
    "                x = self.dropout(x) #apply dropout\n",
    "                \n",
    "        x = self.output(x) #apply output weights\n",
    "        \n",
    "        if args.activation is None:\n",
    "            return x\n",
    "        \n",
    "        return args.activation(x, dim=args.dim) #apply activation log softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classical_dl'></a>\n",
    "## Classical Deep Learning\n",
    "Here we train our network on data that is not distributed (therefore this is not yet a federated or encrypted problem). However, this exercise is useful in showing how we can transition from traditional deep learning to federated deep learning.\n",
    "\n",
    "First create a dataset of batch size one. This is realistic since most people would only have their own credit score data. This might be different if we decide to use a secure or trusted third party to manage parts of the data, but we don't trust the credit rating company with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self, in_size, out_size, hidden_layers,\n",
    "                       activation=F.softmax, dim=-1):\n",
    "        self.batch_size = 1\n",
    "        self.drop_p = None\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.001\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.precision_fractional=10\n",
    "        self.activation = activation\n",
    "        self.dim = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(data[i], target[i]) for i in range(len(data))]\n",
    "\n",
    "#instantiate model\n",
    "in_size = data[0].shape[0]\n",
    "out_size = 2\n",
    "hidden_layers=[30,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.0000,  30.8300,   0.0000,   1.2500,   0.0000,   0.0000,   1.0000,\n",
       "           0.0000, 202.0000,   0.0000,   0.0000,   1.0000,   0.0000,   1.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           1.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   1.0000,   0.0000,   1.0000,   0.0000,   0.0000],\n",
       "        grad_fn=<SelectBackward>), tensor([1., 0.]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data, _target = dataset[0]\n",
    "_data, _target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, datasets, criterion):\n",
    "    #use a simple stochastic gradient descent optimizer\n",
    "    #define optimizer for each model\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=args.lr)\n",
    "    steps=0\n",
    "    model.train() #training mode\n",
    "    for e in range(1, args.epochs+1):\n",
    "        running_loss=0\n",
    "        for ii, (data,target) in enumerate(datasets): #iterates over pointers to remote data\n",
    "            steps+=1\n",
    "            optimizer.zero_grad()#zero out gradients so that one forward pass doesnt pick up previous forward's gradients\n",
    "            outputs = model.forward(data) #make prediction\n",
    "            outputs = outputs.reshape(1,-1) #get shape of (1,2) as we need at least two dimension\n",
    "            loss = criterion(outputs, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #print(f\"step: {steps}\", loss.item())\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "        print(f'Epoch: {e} \\tLoss: {running_loss/len(datasets):.6f}')\n",
    "        running_loss=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments(in_size, out_size, hidden_layers, activation=F.softmax, dim=1)\n",
    "base_model = Model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 0.181214\n",
      "Epoch: 2 \tLoss: 0.177997\n",
      "Epoch: 3 \tLoss: 0.177718\n",
      "Epoch: 4 \tLoss: 0.186159\n",
      "Epoch: 5 \tLoss: 0.178692\n",
      "Epoch: 6 \tLoss: 0.186108\n",
      "Epoch: 7 \tLoss: 0.178352\n",
      "Epoch: 8 \tLoss: 0.176986\n",
      "Epoch: 9 \tLoss: 0.176078\n",
      "Epoch: 10 \tLoss: 0.179313\n"
     ]
    }
   ],
   "source": [
    "model = copy.deepcopy(base_model) #exact replica of base model\n",
    "train(model, dataset, nn.MSELoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use PyTorch's `Dataset` class to make the processing of data a little easier, but for the purpose of this example it will not give any clear benefits. If you would like to read more about PyTorch's abstract `Dataset` class [read here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html), with another example [here](https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel). Generally speaking, using `Dataset` and `DataLoader` makes the handling of training and testing data much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "dataset_ = TensorDataset(data, target)\n",
    "data_loader = DataLoader(dataset_, batch_size=1, shuffle=False) #this gives us an identical implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 0.181214\n",
      "Epoch: 2 \tLoss: 0.177997\n",
      "Epoch: 3 \tLoss: 0.177718\n",
      "Epoch: 4 \tLoss: 0.186159\n",
      "Epoch: 5 \tLoss: 0.178692\n",
      "Epoch: 6 \tLoss: 0.186108\n",
      "Epoch: 7 \tLoss: 0.178352\n",
      "Epoch: 8 \tLoss: 0.176986\n",
      "Epoch: 9 \tLoss: 0.176078\n",
      "Epoch: 10 \tLoss: 0.179313\n",
      "CPU times: user 2.48 s, sys: 79.7 ms, total: 2.56 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#training loss will look a little different since the dataset is shuffled\n",
    "model = copy.deepcopy(base_model)\n",
    "train(model, data_loader, nn.MSELoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a credit application model that is training on our data. However, this is by no means yet federated learning. The implementation above simply trains a model with a batch size of 1. We will federate the model in the upcoming section [here]()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.183px",
    "left": "910px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
