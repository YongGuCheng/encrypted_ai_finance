{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Private and Ecrypted AI - Credit Approval Application\n",
    "1. [Data Preparation & Setup](#data_prep)\n",
    "2. [Classical Deep Learning](#classical_dl)\n",
    "3. [Federated Deep Learning](#federated_dl) <br>\n",
    "   3.1 Secured Multi-Party Computation (SMPC)\n",
    "4. [Encrypted Deep Learning](#encrypted_dl)\n",
    "   \n",
    "   \n",
    "<hr>\n",
    "\n",
    "_Notes_ <br>This project was inspired by lectures of [Andrew Trask](https://iamtrask.github.io/) in the [Private AI Scholarship Challenge on Udacity](https://www.udacity.com/facebook-AI-scholarship). Furthermore, segments of the code are inspired by the [PySyft tutorials on GitHub](https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials); an excellent resource for people starting off with Private AI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_prep'></a>\n",
    "## Data Preparation\n",
    "- only using non-NaN values. I drop NaN values because the dataset is not very big regardless, and we are not dropping very many values.\n",
    "- Convert binary variables to a numeric representation, and one-hot-encode categorical variables. We do not want to use label encoder since a label encoder would make it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ f\"A{i}\" for i in range(1,16)]\n",
    "cols.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653, 16) \n",
      " ------- \n",
      "\n",
      "  A1     A2    A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 label\n",
      "0  b  30.83  0.00  u  g  w  v  1.25  t   t    1   f   g  00202    0     +\n",
      "1  a  58.67  4.46  u  g  q  h  3.04  t   t    6   f   g  00043  560     +\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/crx.data', names=cols)\\\n",
    "    .replace(to_replace='?', value=np.nan).dropna()\n",
    "print(df.shape, \"\\n ------- \\n\")\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(df, col):\n",
    "    u = df[col].unique()\n",
    "    mapping =dict(zip(u, [i for i in range(0,len(u))]))\n",
    "    return df[col].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    b\n",
       "1    a\n",
       "2    a\n",
       "3    b\n",
       "4    b\n",
       "Name: A1, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.A1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to float\n",
    "for col in ['A2', 'A3', 'A8', 'A11', 'A14', 'A15']:\n",
    "    df[col] = df[col].astype(float)\n",
    "    \n",
    "#binarize\n",
    "for col in ['A1', 'A9', 'A10', 'A12', 'label']:\n",
    "    df[col] = to_binary(df, col)\n",
    "    \n",
    "onehot_cols = ['A4', 'A5', 'A6', 'A7', 'A13']\n",
    "\n",
    "#perform one hot encoding, and drop original columns\n",
    "df  = df.join(pd.get_dummies(df[onehot_cols], dtype=int))\\\n",
    "                                .drop(onehot_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1         int64\n",
       "A2       float64\n",
       "A3       float64\n",
       "A8       float64\n",
       "A9         int64\n",
       "A10        int64\n",
       "A11      float64\n",
       "A12        int64\n",
       "A14      float64\n",
       "A15      float64\n",
       "label      int64\n",
       "A4_l       int64\n",
       "A4_u       int64\n",
       "A4_y       int64\n",
       "A5_g       int64\n",
       "A5_gg      int64\n",
       "A5_p       int64\n",
       "A6_aa      int64\n",
       "A6_c       int64\n",
       "A6_cc      int64\n",
       "A6_d       int64\n",
       "A6_e       int64\n",
       "A6_ff      int64\n",
       "A6_i       int64\n",
       "A6_j       int64\n",
       "A6_k       int64\n",
       "A6_m       int64\n",
       "A6_q       int64\n",
       "A6_r       int64\n",
       "A6_w       int64\n",
       "A6_x       int64\n",
       "A7_bb      int64\n",
       "A7_dd      int64\n",
       "A7_ff      int64\n",
       "A7_h       int64\n",
       "A7_j       int64\n",
       "A7_n       int64\n",
       "A7_o       int64\n",
       "A7_v       int64\n",
       "A7_z       int64\n",
       "A13_g      int64\n",
       "A13_p      int64\n",
       "A13_s      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>...</th>\n",
       "      <th>A7_ff</th>\n",
       "      <th>A7_h</th>\n",
       "      <th>A7_j</th>\n",
       "      <th>A7_n</th>\n",
       "      <th>A7_o</th>\n",
       "      <th>A7_v</th>\n",
       "      <th>A7_z</th>\n",
       "      <th>A13_g</th>\n",
       "      <th>A13_p</th>\n",
       "      <th>A13_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2    A3    A8  A9  A10  A11  A12    A14    A15  ...  A7_ff  A7_h  \\\n",
       "0   0  30.83  0.00  1.25   0    0  1.0    0  202.0    0.0  ...      0     0   \n",
       "1   1  58.67  4.46  3.04   0    0  6.0    0   43.0  560.0  ...      0     1   \n",
       "\n",
       "   A7_j  A7_n  A7_o  A7_v  A7_z  A13_g  A13_p  A13_s  \n",
       "0     0     0     0     1     0      1      0      0  \n",
       "1     0     0     0     0     0      1      0      0  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Real People's Data\n",
    "\n",
    "To illustrate how this model would work in real life, I want to simulate this data belonging to people. I am generating random names to be associated with each row. I know that this is not an ideal example since I am infact starting with the data all collated on my computer with peoples names and data being directly exposed. Not differentially private at all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Moon'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import names #used to get random names\n",
    "names.get_first_name()+' ' +names.get_last_name() #call random name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "used_names = set()\n",
    "for idx in range(len(df)):\n",
    "    name = names.get_first_name()+' ' +names.get_last_name()\n",
    "    while name in used_names:\n",
    "        name = names.get_first_name()+' ' +names.get_last_name()\n",
    "        \n",
    "    used_names.add(name)\n",
    "    users.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>...</th>\n",
       "      <th>A7_h</th>\n",
       "      <th>A7_j</th>\n",
       "      <th>A7_n</th>\n",
       "      <th>A7_o</th>\n",
       "      <th>A7_v</th>\n",
       "      <th>A7_z</th>\n",
       "      <th>A13_g</th>\n",
       "      <th>A13_p</th>\n",
       "      <th>A13_s</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Michael Berry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sara Hoyos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2    A3    A8  A9  A10  A11  A12    A14    A15  ...  A7_h  A7_j  \\\n",
       "0   0  30.83  0.00  1.25   0    0  1.0    0  202.0    0.0  ...     0     0   \n",
       "1   1  58.67  4.46  3.04   0    0  6.0    0   43.0  560.0  ...     1     0   \n",
       "\n",
       "   A7_n  A7_o  A7_v  A7_z  A13_g  A13_p  A13_s           name  \n",
       "0     0     0     1     0      1      0      0  Michael Berry  \n",
       "1     0     0     0     0      1      0      0     Sara Hoyos  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'] = users\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features and labels as numpy arrays which we can convert to tensors\n",
    "features = df.drop(['label', 'name'], axis=1).values.astype(float)\n",
    "labels = df['label'].values.astype(float)\n",
    "#labels=pd.get_dummies(df['label']).values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "I am using PyTorch to create a neural network to classify whether someone is accepted for credit or not. PyTorch integrates will with PySyft, the package used to encrypt our deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import syft as sy\n",
    "import torch as th\n",
    "\n",
    "data = th.tensor(features, dtype=th.float32, requires_grad=True)\n",
    "target = th.tensor(labels, dtype=th.int64, requires_grad=False).reshape(-1,1)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    '''\n",
    "    Neural Network Example Model\n",
    "    \n",
    "    Attributes\n",
    "    :hidden_layers (nn.ModuleList) - hidden units and dimensions for each layer of network\n",
    "    :output (nn.Linear) - final fully-connected layer that handles output for model\n",
    "    :dropout (nn.Dropout) - handling of layer-wise drop-out parameter\n",
    "    \n",
    "    Functions\n",
    "    :forward - handling of forward pass of datum through the network.\n",
    "    '''\n",
    "    def __init__(self, args):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(args.in_size, args.hidden_layers[0])])\n",
    "\n",
    "        #create hidden layers\n",
    "        layer_sizes = zip(args.hidden_layers[:-1], args.hidden_layers[1:]) #gives input/output sizes for each layer\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        self.output = nn.Linear(args.hidden_layers[-1], args.out_size)\n",
    "        self.dropout = nn.Dropout(p=args.drop_p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x)) #apply relu to each hidden node\n",
    "            x = self.dropout(x) #apply dropout\n",
    "        x = self.output(x) #apply output weights\n",
    "        return F.log_softmax(x, dim=-1) #apply activation log softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classical_dl'></a>\n",
    "## Classical Deep Learning\n",
    "Here we train our network on data that is not distributed (therefore this is not yet a federated or encrypted problem). However, this exercise is useful in showing how we can transition from traditional deep learning to federated deep learning.\n",
    "\n",
    "First create a dataset of batch size one. This is realistic since most people would only have their own credit score data. This might be different if we decide to use a secure or trusted third party to manage parts of the data, but we don't trust the credit rating company with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self, in_size, out_size, hidden_layers):\n",
    "        self.batch_size = 1\n",
    "        self.drop_p = 0.2\n",
    "        self.epochs = 1\n",
    "        self.lr = 0.01\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.precision_fractional=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(data[i], target[i]) for i in range(len(data))]\n",
    "\n",
    "#instantiate model\n",
    "in_size = data[0].shape[0]\n",
    "out_size = 2\n",
    "hidden_layers=[21,10]\n",
    "\n",
    "args = Arguments(in_size, out_size, hidden_layers)\n",
    "model = Model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.0000,  30.8300,   0.0000,   1.2500,   0.0000,   0.0000,   1.0000,\n",
       "           0.0000, 202.0000,   0.0000,   0.0000,   1.0000,   0.0000,   1.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           1.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   1.0000,   0.0000,   1.0000,   0.0000,   0.0000],\n",
       "        grad_fn=<SelectBackward>), tensor([0]))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data, _target = dataset[0]\n",
    "_data, _target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=42, out_features=21, bias=True)\n",
       "    (1): Linear(in_features=21, out_features=10, bias=True)\n",
       "  )\n",
       "  (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = optim.SGD(params=model.parameters(), lr=0.01) #use a simple stochastic gradient descent optimizer\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, datasets, epochs, criterion, optimizer):\n",
    "    \n",
    "    steps=0\n",
    "    model.train() #training mode\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        running_loss=0\n",
    "        for ii, (data,target) in enumerate(datasets): #iterates over pointers to remote data\n",
    "            steps+=1\n",
    "            optimizer.zero_grad()#zero out gradients so that one forward pass doesnt pick up previous forward's gradients\n",
    "            outputs = model.forward(data) #make prediction\n",
    "            outputs = outputs.reshape(1,-1) #get shape of (1,2) as we need at least two dimension\n",
    "            loss = criterion(outputs, target)\n",
    "            #loss = ((outputs - target.float())**2).sum()\n",
    "            '''\n",
    "            print(outputs, target, outputs-target.float())\n",
    "            print(outputs.shape[0])\n",
    "            print(loss)\n",
    "            break\n",
    "            '''\n",
    "            \n",
    "            #loss = criterion(outputs,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #print(f\"step: {steps}\", loss.item())\n",
    "            running_loss+=loss.item()\n",
    "            #code below courtesy of udacity\n",
    "        print('Epoch: {}  \\tLoss: {:.6f}'.format(e, running_loss/ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  \tLoss: 13.095540\n",
      "Epoch: 2  \tLoss: 10.880752\n",
      "Epoch: 3  \tLoss: 10.172429\n",
      "Epoch: 4  \tLoss: 11.306624\n",
      "Epoch: 5  \tLoss: 9.129770\n",
      "Epoch: 6  \tLoss: 11.926081\n",
      "Epoch: 7  \tLoss: 8.952114\n",
      "Epoch: 8  \tLoss: 11.407958\n",
      "Epoch: 9  \tLoss: 9.281020\n",
      "Epoch: 10  \tLoss: 8.081562\n",
      "Epoch: 11  \tLoss: 9.427256\n",
      "Epoch: 12  \tLoss: 12.676820\n",
      "Epoch: 13  \tLoss: 13.583254\n",
      "Epoch: 14  \tLoss: 13.155210\n",
      "Epoch: 15  \tLoss: 13.120368\n",
      "Epoch: 16  \tLoss: 7.823706\n",
      "Epoch: 17  \tLoss: 8.213576\n",
      "Epoch: 18  \tLoss: 9.912454\n",
      "Epoch: 19  \tLoss: 11.029417\n",
      "Epoch: 20  \tLoss: 10.667659\n"
     ]
    }
   ],
   "source": [
    "train(model, dataset, 20, nn.NLLLoss(), opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use PyTorch's `Dataset` class to make the processing of data a little easier, but for the purpose of this example it will not give any clear benefits. If you would like to read more about PyTorch's abstract `Dataset` class [read here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html), with another example [here](https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel). Generally speaking, using `Dataset` and `DataLoader` makes the handling of training and testing data much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "dataset_ = TensorDataset(data, target.view(-1))\n",
    "data_loader = DataLoader(dataset_, batch_size=1, shuffle=False) #this gives us an identical implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  \tLoss: 12.761351\n",
      "Epoch: 2  \tLoss: 12.416610\n",
      "Epoch: 3  \tLoss: 8.303963\n",
      "Epoch: 4  \tLoss: 9.588416\n",
      "Epoch: 5  \tLoss: 9.849396\n",
      "Epoch: 6  \tLoss: 13.168025\n",
      "Epoch: 7  \tLoss: 9.613965\n",
      "Epoch: 8  \tLoss: 11.084587\n",
      "Epoch: 9  \tLoss: 8.233302\n",
      "Epoch: 10  \tLoss: 11.107691\n",
      "Epoch: 11  \tLoss: 13.642183\n",
      "Epoch: 12  \tLoss: 9.093729\n",
      "Epoch: 13  \tLoss: 11.157685\n",
      "Epoch: 14  \tLoss: 11.672621\n",
      "Epoch: 15  \tLoss: 11.062177\n",
      "Epoch: 16  \tLoss: 11.021728\n",
      "Epoch: 17  \tLoss: 7.722188\n",
      "Epoch: 18  \tLoss: 14.300213\n",
      "Epoch: 19  \tLoss: 10.351277\n",
      "Epoch: 20  \tLoss: 9.697085\n",
      "CPU times: user 13.2 s, sys: 143 ms, total: 13.3 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#training loss will look a little different since the dataset is shuffled\n",
    "model = Model(args)\n",
    "train(model, data_loader, 20, nn.NLLLoss(), opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a credit application model that is training on our data. However, this is by no means yet federated learning. The implementation above simply trains a model with a batch size of 1. We will federate the model in the upcoming section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"federated_dl\"></a>\n",
    "## Federated Deep Learning\n",
    "The idea behind federated learning is that we train a model on subsets of data (encrypted or otherwise) that never leaves the ownership of an individual. In this example of credit rating scores it would allow people to submit claims without ever losing ownership of their data. It requires very little trust of the party to which the application is being submitted.\n",
    "\n",
    "Even though we currently have our dataset located locally, we want to simulate having many people in our network who each maintain ownership of their data. Therefore we have to create a virtual worker for each datum. The work/data flow in this situation would be as follows:\n",
    "\n",
    "- get pointers to training data on each remote worker <br>\n",
    "**Training Steps:**\n",
    "- send model to remote worker\n",
    "- train model on data located with remote worker\n",
    "- recieve updated model from remote worker\n",
    "- repeat for all workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_workers(n_workers):\n",
    "    return [sy.VirtualWorker(hook, id=name) for name in df.name.str.replace(' ', '').values[:n_workers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0811 21:39:20.400497 140383720941376 hook.py:98] Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(th)\n",
    "workers = connect_to_workers(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<VirtualWorker id:MichaelBerry #objects:309>,\n",
       " <VirtualWorker id:SaraHoyos #objects:329>,\n",
       " <VirtualWorker id:KevinMack #objects:134>,\n",
       " <VirtualWorker id:DominickKern #objects:38>,\n",
       " <VirtualWorker id:SandraSmith #objects:38>]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Data to Remote Worker\n",
    "In reality the data of each person would already be on a remote worker. Either each person's device or aggregated into multiple remote workers by a secure third party.\n",
    "\n",
    "Here we have two options:\n",
    "1. send the data to each worker individually\n",
    "2. use PySyft's implemenation of PyTorch's `Dataset` and `DataLoader`\n",
    "\n",
    "I will use PySyft's `BaseDataset`, `FederatedDataset` and `FederatedDataLoader` since this simplifies dataprocessing for larger applications, even though it is not necessary for this example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:63791601495 -> MichaelBerry:48980532036]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1\n",
    "remote_dataset = []\n",
    "for i in range(len(dataset)):\n",
    "    d, t = dataset[i]\n",
    "    \n",
    "    r_d = d.send(workers[i])\n",
    "    r_t = t.send(workers[i])\n",
    "    \n",
    "    remote_dataset.append((r_d, r_t))\n",
    "    \n",
    "r_d, r_t = remote_dataset[0]\n",
    "r_d #this is now a pointer to remote data rather than an actual tensor on our device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MichaelBerry', 'SaraHoyos', 'KevinMack', 'DominickKern', 'SandraSmith']\n"
     ]
    }
   ],
   "source": [
    "# Option 2\n",
    "# Cast the result in BaseDatasets\n",
    "remote_dataset_list = []\n",
    "for i in range(len(dataset)):\n",
    "    d, t = dataset[i] #get data\n",
    "\n",
    "    #send to worker before adding to dataset\n",
    "    r_d = d.reshape(1,-1).send(workers[i])\n",
    "    r_t = t.send(workers[i])\n",
    "    \n",
    "    dtset = sy.BaseDataset(r_d, r_t)\n",
    "    remote_dataset_list.append(dtset)\n",
    "\n",
    "# Build the FederatedDataset object\n",
    "remote_dataset = sy.FederatedDataset(remote_dataset_list)\n",
    "print(remote_dataset.workers[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = sy.FederatedDataLoader(remote_dataset, batch_size=1, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new training logic to reflect federated learning\n",
    "def federated_train(model, datasets, epochs, criterion, optimizer):\n",
    "    print(f'Federated Training on {len(datasets)} remote workers (dataowners)')\n",
    "    steps=0\n",
    "    model.train() #training mode\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        running_loss=0\n",
    "        for ii, (data,target) in enumerate(datasets): #iterates over pointers to remote data\n",
    "            steps+=1\n",
    "            \n",
    "            #FEDERATION STEP\n",
    "            model.send(data.location) #send model to remote worker\n",
    "            \n",
    "            #NB the steps below all happen remotely\n",
    "            optimizer.zero_grad()#zero out gradients so that one forward pass doesnt pick up previous forward's gradients\n",
    "            outputs = model.forward(data) #make prediction\n",
    "            outputs = outputs.reshape(1,-1) #get shape of (1,2) as we need at least two dimension\n",
    "            loss = criterion(outputs,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #FEDERATION STEP\n",
    "            model.get() #get model with new gradients back from remote worker\n",
    "            \n",
    "            #FEDERATION STEP\n",
    "            _loss = loss.get() #get loss from remote worker\n",
    "            running_loss+=_loss\n",
    "            \n",
    "            print_every=100\n",
    "            if steps % print_every == 0:\n",
    "                print('Train Epoch: {} [{}/{}]  \\tLoss: {:.6f}'.format(\n",
    "                    e, ii+1, len(datasets), _loss/print_every))\n",
    "                \n",
    "                running_loss=0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated Training on 653 remote workers (dataowners)\n",
      "Train Epoch: 1 [100/653]  \tLoss: 0.005786\n",
      "Train Epoch: 1 [200/653]  \tLoss: 0.004275\n",
      "Train Epoch: 1 [300/653]  \tLoss: 0.006068\n",
      "Train Epoch: 1 [400/653]  \tLoss: 0.008939\n",
      "Train Epoch: 1 [500/653]  \tLoss: 0.008683\n",
      "Train Epoch: 1 [600/653]  \tLoss: 0.003058\n",
      "CPU times: user 6.17 s, sys: 3.42 ms, total: 6.17 s\n",
      "Wall time: 6.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Model(args)\n",
    "federated_train(model, train_loader, 1, nn.NLLLoss(), opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Viola!_ Now we have a federated model where the data never leaves the ownership of a remote device. We can implement this in a way where each user's device is a worker, or where we have a smaller number of workers (data owners) which are all third parties trusted by the credit applicants to take care of their data.\n",
    "\n",
    "Nevertheless, this **data is not yet encrypted** and we could deduce things specific to the applicant just by getting or looking at the remote data.\n",
    "\n",
    "Notice how the federated model is about 6.5x slower than the non-federated model. This is simply one of the trade-offs that we have to be willing to make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"encrypted_dl\"></a>\n",
    "## Encrypted Deep Learning\n",
    "Encrypted Deep Learning aims to preserve model accuracy and predictive power, without compromising the privacy and identity of individual users in the data. The concept is founded on differential privacy, and can employ numerous encryption techniques. <br> PySyft has employed encryption using secure multi-party computation (SMPC). To learn more about the basics of SMPC and differential privacy [check out my SMPC (PySyft inspired) notebook](http://www.github.com/mkucz95/private_ai_finance/secure_multi_party_computation.ipynb). This will help you understand how the steps below successfuly encrypt data while preserving model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: follow:\n",
    "        \n",
    "https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2010%20-%20Federated%20Learning%20with%20Secure%20Aggregation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are scenarios in which a model will have already been trained, for example from past customer data (before the implementation of differentially private techniques), or that we want to train a new secure model on entirely encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_provider = sy.VirtualWorker(hook, id='crypto_provider')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000, 30.8300,  0.0000,  1.2500,  0.0000], grad_fn=<SliceBackward>),\n",
       " (Wrapper)>FixedPrecisionTensor>tensor([    0, 30830,     0,  1250,     0]))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for SMPC we need to work with integers. \n",
    "#Therefore we convert all decimals to integers depending on the precision we want. \n",
    "#this adds some noise/error to the data\n",
    "data[0][:5], data.fix_precision(5)[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't use the whole dataset for efficiency purpose, but feel free to increase these numbers\n",
    "n_train_items = 10\n",
    "n_test_items = 10\n",
    "\n",
    "def get_private_data_loaders(precision_fractional, workers, crypto_provider):\n",
    "    def secret_share(tensor):\n",
    "        \"\"\"\n",
    "        Transform to fixed precision and secret share a tensor\n",
    "        \"\"\"\n",
    "        return (\n",
    "            tensor\n",
    "            .fix_precision(precision_fractional=precision_fractional)\n",
    "            .share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "        )\n",
    "    \n",
    "    private_train_loader = [\n",
    "        (secret_share(data), secret_share(target))\n",
    "        for i, (data, target) in enumerate(dataset)\n",
    "        if i < n_train_items\n",
    "    ]\n",
    "    \n",
    "    #TODO iterate on this\n",
    "    private_test_loader = [\n",
    "        (secret_share(data), secret_share(target.float()))\n",
    "        for i, (data, target) in enumerate(dataset)\n",
    "        if i < n_test_items\n",
    "    ]\n",
    "    \n",
    "    return private_train_loader, private_test_loader\n",
    "    \n",
    "    \n",
    "private_train_loader, private_test_loader = get_private_data_loaders(\n",
    "    precision_fractional=args.precision_fractional,\n",
    "    workers=workers,\n",
    "    crypto_provider=crypto_provider\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       " \t-> [PointerTensor | me:14753523827 -> MichaelBerry:81453547002]\n",
       " \t-> [PointerTensor | me:27673415801 -> SaraHoyos:6285248345]\n",
       " \t*crypto provider: crypto_provider*,\n",
       " (Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       " \t-> [PointerTensor | me:98745188905 -> MichaelBerry:63953560831]\n",
       " \t-> [PointerTensor | me:76257879237 -> SaraHoyos:58040980791]\n",
       " \t*crypto provider: crypto_provider*)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_train_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> [PointerTensor | me:54906963309 -> MichaelBerry:93683502389]\n",
      "\t-> [PointerTensor | me:63042872172 -> SaraHoyos:73389774872]\n",
      "\t-> [PointerTensor | me:48900505983 -> KevinMack:49273037583]\n",
      "\t*crypto provider: crypto_provider* (Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> [PointerTensor | me:23710369807 -> MichaelBerry:54339387032]\n",
      "\t-> [PointerTensor | me:10964909446 -> SaraHoyos:62114046832]\n",
      "\t-> [PointerTensor | me:40775904429 -> KevinMack:1070431350]\n",
      "\t*crypto provider: crypto_provider*\n"
     ]
    }
   ],
   "source": [
    "smpc_remote_dataset = []\n",
    "for i in range(10):\n",
    "    d, t = dataset[i]\n",
    "\n",
    "    #send to worker before adding to dataset\n",
    "    #securely encrypt across all workers\n",
    "    r_d = d.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad = True) \n",
    "    r_t = t.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True) \n",
    "    \n",
    "    smpc_remote_dataset.append((r_d, r_t))\n",
    "    \n",
    "print(r_d, r_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new training logic to reflect federated learning\n",
    "def encrypted_federated_train(model, datasets, optimizer, args):\n",
    "    print(f'SMPC Training on {len(datasets)} remote workers (dataowners)')\n",
    "    steps=0\n",
    "    model.train() #training mode\n",
    "\n",
    "    for e in range(1, args.epochs+1):\n",
    "        running_loss=0\n",
    "        for ii, (data,target) in enumerate(datasets): #iterates over pointers to remote data\n",
    "            steps+=1\n",
    "            \n",
    "            #NB the steps below all happen remotely\n",
    "            optimizer.zero_grad()#zero out gradients so that one forward pass doesnt pick up previous forward's gradients\n",
    "            outputs = model.forward(data) #make prediction\n",
    "            outputs = outputs.reshape(1,-1) #get shape of (1,2) as we need at least two dimension\n",
    "            loss = ((outputs - target)**2).sum().refresh()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _loss = loss.get().float_precision() #get loss from remote worker and unencrypt\n",
    "            running_loss+=_loss\n",
    "            \n",
    "            print_every=100\n",
    "            if steps % print_every == 0:\n",
    "                print('Train Epoch: {} [{}/{}]  \\tLoss: {:.6f}'.format(\n",
    "                    e, ii+1, len(datasets), _loss/print_every))\n",
    "                \n",
    "                running_loss=0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(args.in_size, 10)\n",
    "        self.fc2 = nn.Linear(10, args.out_size)\n",
    "        self.args = args\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, args.in_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpc_model = Net(args).fix_precision(precision_fractional=args.precision_fractional) \\\n",
    "                        .share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "    \n",
    "smpc_opt = opt.fix_precision(precision_fractional=args.precision_fractional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=42, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMPC Training on 10 remote workers (dataowners)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected device cpu and dtype Float but got device cpu and dtype Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-199-583a558f82d9>\u001b[0m in \u001b[0;36mencrypted_federated_train\u001b[0;34m(model, datasets, optimizer, args)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#get shape of (1,2) as we need at least two dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__isub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36mmethod_with_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 )\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/overload_torch.py\u001b[0m in \u001b[0;36mhook_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(self, _self, other)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sub\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m%=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m  \u001b[0;31m# Wrap around the field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/overload_torch.py\u001b[0m in \u001b[0;36mhook_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(self, shares, other)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mnew_shares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshares\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mnew_shares\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_shares\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_pointer_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# Step 1: route message to appropriate function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# TODO Andrew thinks this is gross, please fix. Instead need to properly deserialize strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# means that there is a wrapper to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p_venv/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected device cpu and dtype Float but got device cpu and dtype Long"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "encrypted_federated_train(smpc_model, private_train_loader, opt, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Note** Using negative log-likelihood loss is not yet supported for multi-party computation. This is due to the nature of computation required for the loss function calculation.\n",
    "\n",
    "_Options_\n",
    "1. train on non-encrypted data (could be differentially private though) and then make predictions using encrypted data. This way we can use NLLLoss for training\n",
    "2. Train the model on federated, encrypted data using mean squared error\n",
    "\n",
    "The type of loss we use [MSELoss](https://pytorch.org/docs/stable/nn.html#mseloss) vs [NLLLoss](https://pytorch.org/docs/stable/nn.html#nllloss) would indicate that we need to handle our target tensors a little differently. These loss functions expect different shapes as the target inputs. Read the documentation if you want to find out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
